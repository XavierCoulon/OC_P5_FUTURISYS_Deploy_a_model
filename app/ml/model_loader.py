import logging
from io import BytesIO
from pathlib import Path

import joblib
import requests
from huggingface_hub import hf_hub_url

MODEL_PATH = Path(__file__).resolve().parent / "random_forest_pipeline.pkl"
# Nom du d√©p√¥t et fichier sur Hugging Face
HF_REPO_ID = "XavierCoulon/futurisys-model"
HF_FILENAME = "random_forest_pipeline.pkl"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


def load_model():
    """Charge le mod√®le ML depuis le fichier en local ou depuis Hugging Face."""
    logging.info(f"üîç Tentative de chargement du mod√®le depuis {MODEL_PATH}")
    if MODEL_PATH.exists():
        try:
            model = joblib.load(MODEL_PATH)
            logging.info("‚úÖ Mod√®le charg√© depuis le fichier local.")
            return model
        except Exception as e:
            logging.error(f"‚ùå √âchec du chargement local : {e}")
    logging.info("üåê T√©l√©chargement du mod√®le depuis Hugging Face...")
    try:
        url = hf_hub_url(
            repo_id=HF_REPO_ID,
            filename=HF_FILENAME,
        )
        response = requests.get(url)
        response.raise_for_status()
        model = joblib.load(BytesIO(response.content))
        logging.info("‚úÖ Mod√®le t√©l√©charg√© et charg√© depuis Hugging Face.")
        return model
    except Exception as e:
        logging.error(f"‚ùå √âchec du t√©l√©chargement depuis Hugging Face : {e}")
        raise RuntimeError("Impossible de charger le mod√®le ML.") from e


model = load_model()
